{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recognize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObQ0R2/T3A91IbM+gCBgX5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amritesh-gaurav/Face-Detection/blob/main/Recognize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 1: Initialize and Setup"
      ],
      "metadata": {
        "id": "nABM-RHuzYri"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AVFE6IKYtLzs"
      },
      "outputs": [],
      "source": [
        "import dlib\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Face Detector from dlib\n",
        "# This allows us to detect faces in images\n",
        "face_detector = dlib.get_frontal_face_detector()"
      ],
      "metadata": {
        "id": "IMxDiXLFxzxz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Pose Predictor from dlib\n",
        "# This allows us to detect landmark points in faces and understand the pose/angle of the face\n",
        "shape_predictor = dlib.shape_predictor('/content/face_recognition/shape_predictor_68_face_landmarks.dat')"
      ],
      "metadata": {
        "id": "9gqG6NC-y5lj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the face recognition model\n",
        "# This is what gives us the face encodings (numbers that identify the face of a particular person)\n",
        "face_recognition_model = dlib.face_recognition_model_v1('/content/face_recognition/dlib_face_recognition_resnet_model_v1.dat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "_jITrwqCy5pS",
        "outputId": "2b2d3bfc-771b-4966-8499-1dacf61a82b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-15eca182f542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the face recognition model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This is what gives us the face encodings (numbers that identify the face of a particular person)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/face_recognition/dlib_face_recognition_resnet_model_v1.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Unable to open /content/face_recognition/dlib_face_recognition_resnet_model_v1.dat for reading."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the tolerance for face comparisons\n",
        "# The lower the number - the stricter the comparison\n",
        "# To avoid false matches, use lower value\n",
        "# To avoid false negatives (i.e. faces of the same person doesn't match), use higher value\n",
        "# 0.5-0.6 works well\n",
        "TOLERANCE = 0.6"
      ],
      "metadata": {
        "id": "gfeNX5TQy5sb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2: Get face encodings from an image"
      ],
      "metadata": {
        "id": "Ya4eydQBzh6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function will take an image and return its face encodings using the neural network\n",
        "def get_face_encodings(path_to_image):\n",
        "    # Load image using scipy\n",
        "    image = scipy.misc.imread(path_to_image)\n",
        "    # Detect faces using the face detector\n",
        "    detected_faces = face_detector(image, 1)\n",
        "    # Get pose/landmarks of those faces\n",
        "    # Will be used as an input to the function that computes face encodings\n",
        "    # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
        "    shapes_faces = [shape_predictor(image, face) for face in detected_faces]\n",
        "    # For every face detected, compute the face encodings\n",
        "    return [np.array(face_recognition_model.compute_face_descriptor(image, face_pose, 1)) for face_pose in shapes_faces]"
      ],
      "metadata": {
        "id": "21lWiWiRy5xk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3a: Compare faces"
      ],
      "metadata": {
        "id": "_cUZk_oDzx_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function takes a list of known faces\n",
        "def compare_face_encodings(known_faces, face):\n",
        "    # Finds the difference between each known face and the given face (that we are comparing)\n",
        "    # Calculate norm for the differences with each known face\n",
        "    # Return an array with True/Face values based on whether or not a known face matched with the given face\n",
        "    # A match occurs when the (norm) difference between a known face and the given face is less than or equal to the TOLERANCE value\n",
        "    return (np.linalg.norm(known_faces - face, axis=1) <= TOLERANCE)"
      ],
      "metadata": {
        "id": "mCSs5UWxy5zr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3b: Find match"
      ],
      "metadata": {
        "id": "voqSV0lPz3hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function returns the name of the person whose image matches with the given face (or 'Not Found')\n",
        "# known_faces is a list of face encodings\n",
        "# names is a list of the names of people (in the same order as the face encodings - to match the name with an encoding)\n",
        "# face is the face we are looking for\n",
        "def find_match(known_faces, names, face):\n",
        "    # Call compare_face_encodings to get a list of True/False values indicating whether or not there's a match\n",
        "    matches = compare_face_encodings(known_faces, face)\n",
        "    # Return the name of the first match\n",
        "    count = 0\n",
        "    for match in matches:\n",
        "        if match:\n",
        "            return names[count]\n",
        "        count += 1\n",
        "    # Return not found if no match found\n",
        "    return 'Not Found'"
      ],
      "metadata": {
        "id": "_aKW773Vy51r"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 4a: Getting face encodings for all faces in the images folder"
      ],
      "metadata": {
        "id": "zlPkqNaEz_pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get path to all the known images\n",
        "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
        "image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('/content/face_recognition/images'))\n",
        "# Sort in alphabetical order\n",
        "image_filenames = sorted(image_filenames)\n",
        "# Get full paths to images\n",
        "paths_to_images = ['/content/face_recognition/images' + x for x in image_filenames]\n",
        "# List of face encodings we have\n",
        "face_encodings = []\n",
        "# Loop over images to get the encoding one by one\n",
        "for path_to_image in paths_to_images:\n",
        "    # Get face encodings from the image\n",
        "    face_encodings_in_image = get_face_encodings(path_to_image)\n",
        "    # Make sure there's exactly one face in the image\n",
        "    if len(face_encodings_in_image) != 1:\n",
        "        print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "        exit()\n",
        "    # Append the face encoding found in that image to the list of face encodings we have\n",
        "    face_encodings.append(get_face_encodings(path_to_image)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "w_qa2NH2y53z",
        "outputId": "348b9a04-b61e-489b-b4b9-349d47697bef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-bc0f28f59ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath_to_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths_to_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Get face encodings from the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mface_encodings_in_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_face_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Make sure there's exactly one face in the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_encodings_in_image\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f9cfb6ae5f0d>\u001b[0m in \u001b[0;36mget_face_encodings\u001b[0;34m(path_to_image)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_face_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Load image using scipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Detect faces using the face detector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdetected_faces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'scipy.misc' has no attribute 'imread'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 4b: Matching each image in test folder with the known faces (one by one)"
      ],
      "metadata": {
        "id": "0Qu6oJRE0I9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get path to all the test images\n",
        "# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n",
        "test_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('test/'))\n",
        "# Get full paths to test images\n",
        "paths_to_test_images = ['test/' + x for x in test_filenames]\n",
        "# Get list of names of people by eliminating the .JPG extension from image filenames\n",
        "names = [x[:-4] for x in image_filenames]\n",
        "# Iterate over test images to find match one by one\n",
        "for path_to_image in paths_to_test_images:\n",
        "    # Get face encodings from the test image\n",
        "    face_encodings_in_image = get_face_encodings(path_to_image)\n",
        "    # Make sure there's exactly one face in the image\n",
        "    if len(face_encodings_in_image) != 1:\n",
        "        print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n",
        "        exit()\n",
        "    # Find match for the face encoding found in this test image\n",
        "    match = find_match(face_encodings, names, face_encodings_in_image[0])\n",
        "    # Print the path of test image and the corresponding match\n",
        "    print(path_to_image, match)"
      ],
      "metadata": {
        "id": "n50hM5tU0Twx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}